{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Da best heart disease classifier in town\n",
    "- 13516083 / Abram Perdanaputra\n",
    "- 13516090 / Timothy Thamrin Andrew Hamonangan Sihombing\n",
    "- 13516093 / Muhammad Farhan\n",
    "- 13516153 / Dimas Aditia Pratikto\n",
    "- 13516155 / Restu Wahyu Kartiko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, train_test_split,GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import numbers\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curve function\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=5, n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to read the `tubes2_HeartDisease_train` and `tubes2_HeartDisease_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_data(data):\n",
    "    \"\"\"Convert dataframe to appropriate types\"\"\"\n",
    "    for x in range(1,5):\n",
    "        data.loc[data['Column3'] == x, 'Column3'] = str(x)\n",
    "\n",
    "    num_col = [4, 5, 6, 8, 9, 10, 12]\n",
    "    \n",
    "    for col in num_col:\n",
    "        col_name = 'Column'+str(col)\n",
    "        data[col_name] = pd.to_numeric(data[col_name], errors='coerce')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def show_data(df, columns):\n",
    "    data = copy.deepcopy(df)\n",
    "    data.columns = columns\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data columns and read data from files\n",
    "\n",
    "heart_disease = {}\n",
    "heart_disease['columns_detail'] = [\n",
    "    'Age', \n",
    "    'Sex', \n",
    "    'Pain type', \n",
    "    'Blood pressure', \n",
    "    'Serum cholesterol', \n",
    "    'Fasting blood sugar > 120mg/dl', \n",
    "    'Resting ECG', \n",
    "    'Max heart rate achieved', \n",
    "    'exercise induced agina', \n",
    "    'ST depression induced by exercise relative to rest', \n",
    "    'Peak exercise ST segment', \n",
    "    'Number of major vessels colored by flourosopy', \n",
    "    'Thal', \n",
    "    'Diagnosis'\n",
    "]\n",
    "heart_disease['train'] = pd.read_csv('../data/tubes2_HeartDisease_train.csv')\n",
    "heart_disease['test'] = pd.read_csv('../data/tubes2_HeartDisease_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease['train'] = fix_data(heart_disease['train'])\n",
    "show_data(heart_disease['train'], heart_disease['columns_detail']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "def preprocess_data(data):\n",
    "    df = copy.deepcopy(data)\n",
    "    \n",
    "    # remove infinity and null\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "#     for i, row in df.iterrows():\n",
    "#         if row['Column11'] == '?':\n",
    "#             df.loc[i, 'Column11'] = np.random.choice(['1', '2', '3'], \\\n",
    "#                                                size=1,\\\n",
    "#                                                p=[0.5570599613152805, 0.3404255319148936, 0.10251450676982592])[0]\n",
    "    \n",
    "    # dropping bad columns\n",
    "    df = df.drop(['Column12', 'Column13'], axis=1)\n",
    "    \n",
    "    # dropping null values\n",
    "    null_array = []\n",
    "    for i, row in df.iterrows():\n",
    "        if check_null(row) > 3:\n",
    "            null_array.append(i)\n",
    "            \n",
    "    null_array.reverse()\n",
    "    for i in null_array:\n",
    "        df = df.drop(df.index[i])\n",
    "\n",
    "    # remove outliers\n",
    "    \n",
    "    # fill null and nan with median\n",
    "    df.loc[data['Column4'].isnull(), 'Column4'] = data['Column4'].median()\n",
    "    df.loc[data['Column5'].isnull(), 'Column5'] = data['Column5'].median()\n",
    "    df.loc[data['Column6'].isnull(), 'Column6'] = data['Column6'].median()\n",
    "    df.loc[data['Column8'].isnull(), 'Column8'] = data['Column8'].median()\n",
    "    df.loc[data['Column9'].isnull(), 'Column9'] = data['Column9'].median()\n",
    "    df.loc[data['Column10'].isnull(), 'Column10'] = data['Column10'].median()\n",
    "    \n",
    "    df.loc[np.isnan(data['Column4']), 'Column4'] = data['Column4'].median()\n",
    "    df.loc[np.isnan(data['Column5']), 'Column5'] = data['Column5'].median()\n",
    "    df.loc[np.isnan(data['Column6']), 'Column6'] = data['Column6'].median()\n",
    "    df.loc[np.isnan(data['Column8']), 'Column8'] = data['Column8'].median()\n",
    "    df.loc[np.isnan(data['Column9']), 'Column9'] = data['Column9'].median()\n",
    "    df.loc[np.isnan(data['Column10']), 'Column10'] = data['Column10'].median()\n",
    "    \n",
    "    df.loc[data['Column7'] == '?', 'Column7'] = '0'\n",
    "    df.loc[data['Column11'] == '?', 'Column11'] = '1'\n",
    "    \n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def check_null(row):\n",
    "    sum = 0\n",
    "    for column in row:\n",
    "        if isinstance(column, numbers.Number) and np.isnan(column):\n",
    "            sum += 1\n",
    "        if not(isinstance(column, numbers.Number)) and column == '?':\n",
    "            sum += 1\n",
    "        if column == None:\n",
    "            sum += 1\n",
    "    return sum\n",
    "\n",
    "def check_outlier(row):\n",
    "    outlier = False\n",
    "    for column in row:\n",
    "        if isinstance(column, numbers.Number) and np.isnan(column):\n",
    "            sum += 1\n",
    "        if not(isinstance(column, numbers.Number)) and column == '?':\n",
    "            sum += 1\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_data(heart_disease['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Distribution on Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Column14'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neighbor = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=num_neighbor, algorithm='ball_tree')\n",
    "\n",
    "# train\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('Column14', axis=1), df.Column14,test_size=0.2)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "knn_f1_scores = cross_val_score(knn, df.loc[:, df.columns != 'Column14']\\\n",
    "                , df['Column14'], cv=cv, scoring='f1_micro')\n",
    "knn_accuracy_scores = cross_val_score(knn, df.loc[:, df.columns != 'Column14']\\\n",
    "                , df['Column14'], cv=cv, scoring='accuracy')\n",
    "print(\"F1 Score: {:.4f} +- {:.4f}\".format(knn_f1_scores.mean(), knn_f1_scores.std()))\n",
    "print(\"Accuracy Score: {:.4f} +- {:.4f}\".format(knn_accuracy_scores.mean(), knn_accuracy_scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "\n",
    "# train\n",
    "X_train,X_test,y_train,y_test=X_train, X_test, y_train, y_test = train_test_split(df.drop('Column14', axis=1), df.Column14,test_size=0.2)\n",
    "\n",
    "gnb_f1_scores = cross_val_score(gnb, df.loc[:, df.columns != 'Column14']\\\n",
    "                , df['Column14'], cv=cv, scoring='f1_micro')\n",
    "gnb_accuracy_scores = cross_val_score(gnb, df.loc[:, df.columns != 'Column14']\\\n",
    "                , df['Column14'], cv=cv, scoring='accuracy')\n",
    "print(\"F1 Score: {:.4f} +- {:.4f}\".format(gnb_f1_scores.mean(), gnb_f1_scores.std()))\n",
    "print(\"Accuracy Score: {:.4f} +- {:.4f}\".format(gnb_accuracy_scores.mean(), gnb_accuracy_scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree (ID3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id3 = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=8, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=8, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
    "            splitter='best')\n",
    "\n",
    "# train\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('Column14', axis=1), df.Column14,test_size=0.2)\n",
    "id3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores\n",
    "id3_f1_scores = cross_val_score(id3, df.loc[:, df.columns != 'Column14']\\\n",
    "                , df['Column14'], cv=cv, scoring='f1_micro')\n",
    "id3_accuracy_scores = cross_val_score(id3, df.loc[:, df.columns != 'Column14']\\\n",
    "                , df['Column14'], cv=cv, scoring='accuracy')\n",
    "print(\"F1 Score: {:.4f} +- {:.4f}\".format(id3_f1_scores.mean(), id3_f1_scores.std()))\n",
    "print(\"Accuracy Score: {:.4f} +- {:.4f}\".format(id3_accuracy_scores.mean(), id3_accuracy_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly=PolynomialFeatures(5)\n",
    "poly_x = poly.fit_transform(df.drop('Column14', axis=1))\n",
    "\n",
    "parameters = {'max_depth':[3,6,9,12,15], 'min_samples_split':[2,4,8,16], 'min_samples_leaf':[1,2,4,8,16], 'max_features':[2,4,8,10]}\n",
    "grid_search = GridSearchCV(id3, parameters, cv=5)\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "print(id3.score(X_test,y_test))\n",
    "print(grid_search.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(id3, \"Plot\", df.drop(\"Column14\",axis=1), df['Column14'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(id3.predict(X_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id3.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "df.loc[:, df.columns != 'b']\n",
    "mlp_f1_scores = cross_val_score(mlp, df.loc[:, df.columns != 'Column14']\\\n",
    "                , df['Column14'], cv=cv, scoring='f1_micro')\n",
    "print(\"F1 Score: {} +- {}\".format(mlp_f1_scores.mean(), mlp_f1_scores.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
